# kubectl apply -f results_mon.yaml
# kubectl exec -it monitor-training-results -- /bin/bash

# Training results are mounted to /develop/results/checkpoints
# - Folders have the naming convention k_{xx}, where xx is an integer value
#   representing the sequence length.
#   - Pytorch lightning generates a folder called `lightning logs`
#       - `rnn` and `lstm` folders contain their respective checkpoints.

# Analysis results are mounted to /develop/results/analysis
# - Folders have the naming convention exp_{xx} where xx is an integer value
#   representing sequence length. 
# - This folder also contains all_measures.pkl, all_loss.pkl, and all_preds.pkl, 
#   which are aggregations of results over all experiments.
# - The folders all_bars, all_loss, all_flipbooks are for convenience - they get
#   generated in the evaulation stage and just provide easy access to plots, figures,
#   etc. 

apiVersion: v1
kind: Pod
metadata:
  name: monitor-training-results
spec:
  containers:
    - name: monitor-training-results
      image: docker.io/kovaleskilab/meep:v3_lightning
      stdin: True
      tty: True
      resources:
        limits:
          memory: 4Gi
          cpu: 2
        requests:
          memory: 4Gi
          cpu: 2
      volumeMounts:
        - name: training-results 
          mountPath: /develop/results
  volumes:
    - name: training-results 
      persistentVolumeClaim:
        claimName: training-results 

  restartPolicy: Never
